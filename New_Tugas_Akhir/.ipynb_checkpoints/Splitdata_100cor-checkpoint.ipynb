{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from scipy.stats.stats import pearsonr\n",
    "import pickle\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "padel_desc = pd.read_csv(r'data/padel_desc.csv')\n",
    "pIC50_target = pd.read_excel(r'data/pIC50_target.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kolom yang dihapus\n",
    "padel_desc = padel_desc.drop([\"Name\"], axis=1)\n",
    "pIC50_target = pIC50_target.drop(['No.'], axis=1)\n",
    "\n",
    "padel_desc.shape, pIC50_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([padel_desc, pIC50_target], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop kolom yang ada duplikat\n",
    "dataset = dataset.loc[:,~dataset.columns.duplicated()]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop kolom yang ada 0\n",
    "dataset = dataset[(dataset.sum(axis=1) != 0)]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop kolom yang ada nan\n",
    "dataset.dropna(axis=1, inplace=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size = 0.2, random_state = 10)\n",
    "train.shape, test.shape\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train, open('data/train_bams.p','wb'))\n",
    "pickle.dump(test, open('data/test_bams.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pickle.load(open('data/train_bams.p','rb'))\n",
    "df_test = pickle.load(open('data/test_bams.p','rb'))\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_train.corr()\n",
    "corr = corr.iloc[:-1,[-1]]\n",
    "corr.sort_values(\"pIC50\", ascending= False, inplace = True)\n",
    "corr = corr.iloc[:100,:]\n",
    "# corr.to_csv (r'data/data_corr.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cek = corr.index.values.tolist()[:100]\n",
    "pickle.dump(cek, open('data/corr_bams.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----------REMOVE FEATURE WITH LOW CORRELATION TO Y RESPONSE---------------------\n",
    "label_ = df_train.columns.values\n",
    "pic50 = df_train.iloc[:,-1]\n",
    "corr_y = [pearsonr(df_train.iloc[:,i],pic50) for i in range(df_train.shape[1])]\n",
    "corr_y = [np.abs(corr_y[i][0]) for i in range(df_train.shape[1])]\n",
    "corr_lim = 0.20\n",
    "hi_corr = []\n",
    "for i in range(len(corr_y)):\n",
    "    if corr_y[i] > corr_lim:\n",
    "        hi_corr.append(i)\n",
    "\n",
    "corr_low = corr_y\n",
    "        \n",
    "# label_idx = label_[hi_corr]\n",
    "# train = train.loc[:,label_idx]\n",
    "# print(\"descriptor number after removing low correlation with target: {}\".format(train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_train.T\n",
    "df_corr['corr'] = corr_low\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------REMOVE FEATURE WITH HIGH CORRELATION TO OTHER FEATURE---------------------\n",
    "# # re-calculate correlation with pic50\n",
    "# label_ = train.columns.values\n",
    "# corr_y = [pearsonr(train.iloc[:,i],pic50) for i in range(train.shape[1])]\n",
    "# corr_y = [np.abs(corr_y[i][0]) for i in range(train.shape[1])]\n",
    "# desc_num = train.shape[1]\n",
    "# # calculate correlation for each descriptor\n",
    "# corr_matrix = np.corrcoef(train.T)\n",
    "# corr_lim = 0.80\n",
    "# low_corr = np.arange(desc_num).tolist()\n",
    "# tmp = np.arange(desc_num).tolist()\n",
    "# for i in np.arange(desc_num):\n",
    "#     tmp.remove(i)\n",
    "#     for j in tmp:\n",
    "#         corr_ = np.abs(corr_matrix[i,j])\n",
    "#         if corr_ >= corr_lim:\n",
    "#             if corr_y[i] > corr_y[j]:\n",
    "#                 if j in low_corr:\n",
    "#                     low_corr.remove(j)\n",
    "#             else:\n",
    "#                 if i in low_corr:\n",
    "#                     low_corr.remove(i)\n",
    "# label_idx = label_[low_corr]\n",
    "# df_train = train.loc[:,label_idx]\n",
    "# print(\"descriptor number after removing high correlation descriptor: {}\".format(df_train.shape[1]))\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_corr.sort_values(by='corr', ascending=False)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_top100 = df_corr.iloc[1:101,-1]\n",
    "corr_desc100 = corr_top100.index\n",
    "corr_desc100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(corr_desc100, open('data/corr_desc100.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
